{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_RMSE(y_pred, y_gt):\n",
    "    rmse_value = math.sqrt(np.mean((y_pred - y_gt)**2))\n",
    "    print(\"RMSE: {0:.2f}\".format(rmse_value))\n",
    "    return rmse_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(train_df):\n",
    "    doc_list = train_df['식사내용'].apply(lambda x: ' '.join(x[:-1].split(','))).tolist()\n",
    "    time_list = train_df['time'].tolist()\n",
    "    for i in range(len(doc_list)):\n",
    "        doc_list[i] = \"{} {}\".format(time_list[i], doc_list[i])\n",
    "    Y = train_df['수량'].values.reshape(-1,1)\n",
    "    return doc_list, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path):\n",
    "    train_df = pd.read_csv(data_path, sep='\\t')\n",
    "    train_df.info()\n",
    "    doc_list, Y = process_df(train_df)\n",
    "    return doc_list, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './train_data.tsv'\n",
    "train_df = pd.read_csv(train_data_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>time</th>\n",
       "      <th>식사내용</th>\n",
       "      <th>매출일자</th>\n",
       "      <th>수량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030301</td>\n",
       "      <td>아침</td>\n",
       "      <td>과일샐러드,닭죽,돈육마늘장조림,떡만두국,부추김무침,쌀밥,딸기잼(중),비엔나구이,스크...</td>\n",
       "      <td>20030301.0</td>\n",
       "      <td>37.472924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030301</td>\n",
       "      <td>저녁</td>\n",
       "      <td>감자으깸샐러드,비프까스,스위트피클,쌀밥,옥수수스프,</td>\n",
       "      <td>20030301.0</td>\n",
       "      <td>19.566787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030301</td>\n",
       "      <td>점심</td>\n",
       "      <td>골뱅이야채무침,새우맛살튀김,쌀밥(사무직),열무겉절이,칼국수,</td>\n",
       "      <td>20030301.0</td>\n",
       "      <td>31.191336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030302</td>\n",
       "      <td>아침</td>\n",
       "      <td>계란죽,곤약멸치조림,김치국,마카로니샐러드,쌀밥,오징어회무침,딸기잼(중),삶은계란,야...</td>\n",
       "      <td>20030302.0</td>\n",
       "      <td>36.101083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030302</td>\n",
       "      <td>저녁</td>\n",
       "      <td>계란탕,단무지잔파무침,자장소스,잡채밥,탕수만두,</td>\n",
       "      <td>20030302.0</td>\n",
       "      <td>21.949458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         일자 time                                               식사내용  \\\n",
       "0  20030301   아침  과일샐러드,닭죽,돈육마늘장조림,떡만두국,부추김무침,쌀밥,딸기잼(중),비엔나구이,스크...   \n",
       "1  20030301   저녁                       감자으깸샐러드,비프까스,스위트피클,쌀밥,옥수수스프,   \n",
       "2  20030301   점심                  골뱅이야채무침,새우맛살튀김,쌀밥(사무직),열무겉절이,칼국수,   \n",
       "3  20030302   아침  계란죽,곤약멸치조림,김치국,마카로니샐러드,쌀밥,오징어회무침,딸기잼(중),삶은계란,야...   \n",
       "4  20030302   저녁                         계란탕,단무지잔파무침,자장소스,잡채밥,탕수만두,   \n",
       "\n",
       "         매출일자         수량  \n",
       "0  20030301.0  37.472924  \n",
       "1  20030301.0  19.566787  \n",
       "2  20030301.0  31.191336  \n",
       "3  20030302.0  36.101083  \n",
       "4  20030302.0  21.949458  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "아침     172889.386282\n",
       "저녁      99269.891697\n",
       "점심     141973.574007\n",
       "점심2     57353.140794\n",
       "Name: 수량, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('time')['수량'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20606 entries, 0 to 20605\n",
      "Data columns (total 5 columns):\n",
      "일자      20606 non-null int64\n",
      "time    20606 non-null object\n",
      "식사내용    20606 non-null object\n",
      "매출일자    20606 non-null float64\n",
      "수량      20606 non-null float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 805.0+ KB\n",
      "20606\n",
      "아침 과일샐러드 닭죽 돈육마늘장조림 떡만두국 부추김무침 쌀밥 딸기잼(중) 비엔나구이 스크램블에그(경양식) 야채샐러드 크림스프(경양식) 토스트&모닝빵\n"
     ]
    }
   ],
   "source": [
    "contents, data_y = get_data(train_data_path)\n",
    "print(len(contents))\n",
    "print(contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_vectorizer(vectorizer, contents):\n",
    "    return vectorizer.fit_transform(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_X, data_y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=818)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(vectorizer_objs, model_objs, contents, data_y):\n",
    "    for each_vectorizer in vectorizer_objs:\n",
    "        data_X = do_vectorizer(each_vectorizer, contents)\n",
    "        X_train, X_test, y_train, y_test = split_data(data_X, data_y)\n",
    "        for each_model in model_objs:\n",
    "            each_model.fit(X_train, y_train)\n",
    "            print(\"vectorizer name : {}\".format(str(each_vectorizer)))\n",
    "            print(\"model name : {}\".format(str(each_model)))\n",
    "            do_RMSE(y_pred=each_model.predict(X_test), y_gt=y_test)\n",
    "            do_RMSE(y_pred=each_model.predict(X_train), y_gt=y_train)\n",
    "            print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_objs = [TfidfVectorizer(max_features=30,ngram_range=range(1, 3)),\n",
    "                   TfidfVectorizer(max_features=100,ngram_range=range(1, 3)),\n",
    "                   TfidfVectorizer(max_features=500,ngram_range=range(1, 3)),\n",
    "                   TfidfVectorizer(max_features=1000,ngram_range=range(1, 3)),\n",
    "                   TfidfVectorizer(max_features=2000,ngram_range=range(1, 3)),\n",
    "                   CountVectorizer(max_features=30, ngram_range=range(1, 3)),\n",
    "                   CountVectorizer(max_features=100, ngram_range=range(1, 3)),\n",
    "                   CountVectorizer(max_features=500, ngram_range=range(1, 3)),\n",
    "                   CountVectorizer(max_features=1000, ngram_range=range(1, 3)),\n",
    "                   CountVectorizer(max_features=2000, ngram_range=range(1, 3))\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_objs = [LinearRegression(normalize=False), LinearRegression(normalize=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=30, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.91\n",
      "RMSE: 8.93\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=30, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.91\n",
      "RMSE: 8.93\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=100, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.82\n",
      "RMSE: 8.86\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=100, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.82\n",
      "RMSE: 8.86\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.55\n",
      "RMSE: 8.37\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.55\n",
      "RMSE: 8.37\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.61\n",
      "RMSE: 8.12\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.61\n",
      "RMSE: 8.12\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=2000, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.80\n",
      "RMSE: 7.65\n",
      "==================================================\n",
      "vectorizer name : TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=2000, min_df=1,\n",
      "        ngram_range=range(1, 3), norm='l2', preprocessor=None,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.80\n",
      "RMSE: 7.65\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=30, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.86\n",
      "RMSE: 8.89\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=30, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.86\n",
      "RMSE: 8.89\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=100, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.77\n",
      "RMSE: 8.77\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=100, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.77\n",
      "RMSE: 8.77\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.52\n",
      "RMSE: 8.36\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=500, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.52\n",
      "RMSE: 8.36\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.54\n",
      "RMSE: 8.11\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.54\n",
      "RMSE: 8.11\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=2000, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "RMSE: 8.77\n",
      "RMSE: 7.67\n",
      "==================================================\n",
      "vectorizer name : CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=2000, min_df=1,\n",
      "        ngram_range=range(1, 3), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "model name : LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "RMSE: 8.77\n",
      "RMSE: 7.67\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "do_train(vectorizer_objs, model_objs, contents, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
